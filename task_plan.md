# ðŸ“‹ Task Plan â€” B.L.A.S.T. Project Blueprint
## ZYROX AI Intelligence Dashboard

> **Status:** ï¿½ IN PROGRESS â€” Phase 5 remaining (Automation Trigger)
> **Protocol:** B.L.A.S.T. (Blueprint â†’ Link â†’ Architect â†’ Stylize â†’ Trigger)
> **Last Updated:** 2026-02-22 23:36 IST

---

## ðŸŽ¯ Phase Tracker

| Phase | Name      | Status        | Completed                                                |
|-------|-----------|---------------|----------------------------------------------------------|
| 0     | Init      | âœ… Complete   | `gemini.md`, `task_plan.md`, `findings.md`, `progress.md` created |
| 1     | Blueprint | âœ… Complete   | Discovery answered, schema defined, blueprint approved   |
| 2     | Link      | âœ… Complete   | All sources verified; Supabase + Reddit API connected    |
| 3     | Architect | âœ… Complete   | All Layer 3 tools built, SOPs written, data flowing      |
| 4     | Stylize   | âœ… Complete   | ZYROX brand applied, dashboard live on port 3737         |
| 5     | Trigger   | ðŸŸ¡ In Progress | Supabase live; Windows Task Scheduler not yet configured |

---

## âœ… Phase 0: Init â€” COMPLETE

- [x] `gemini.md` â€” Project Constitution created
- [x] `task_plan.md` â€” Phase tracker initialized
- [x] `findings.md` â€” Research log initialized
- [x] `progress.md` â€” Append-only execution log initialized

---

## âœ… Phase 1: Blueprint â€” COMPLETE

- [x] Discovery Q1 â€” North Star: Beautiful interactive AI news dashboard, last 24h
- [x] Discovery Q2 â€” Integrations: Web scraping (no keys) â†’ Supabase + Reddit API (Phase 5)
- [x] Discovery Q3 â€” Source of Truth: bensbites.beehiiv.com, therundown.ai, reddit.com
- [x] Discovery Q4 â€” Payload: Local dashboard + 24h auto-refresh + save articles + Supabase cloud
- [x] Discovery Q5 â€” Rules: Only show new content, dedup by URL hash, saved articles persist
- [x] JSON Data Schema defined in `gemini.md` (Article schema v1.0)
- [x] Blueprint approved â†’ Coding started

---

## âœ… Phase 2: Link â€” COMPLETE

- [x] `.env` file created with all credentials
- [x] **Ben's Bites** â€” HTML scrape fallback working (beehiiv RSS is subscriber-gated)
- [x] **The Rundown** â€” `therundown.ai` homepage scrape working âœ… 10 articles
- [x] **Reddit** â€” Public JSON API working âœ… 5â€“7 posts per run (PRAW ready when credentials added)
- [x] **Supabase** â€” Connection tested âœ… `ACTIVE_HEALTHY` (ap-south-1)
- [x] Handshake test: `python tools/supabase_sync.py --test` â†’ PASS

---

## âœ… Phase 3: Architect â€” COMPLETE

### SOPs Written
- [x] `architecture/SOP-001-scraper.md` â€” Scraper architecture + edge cases
- [x] `architecture/SOP-002-store.md` â€” Merge, dedup, save/unsave logic
- [x] `architecture/SOP-003-supabase.md` â€” Supabase sync + RLS + data flow

### Layer 3 Tools Built
- [x] `tools/scraper.py` â€” Multi-source scraper (Ben's Bites, The Rundown, Reddit)
- [x] `tools/store.py` â€” Merge, dedup, local JSON persistence + Supabase threading
- [x] `tools/supabase_sync.py` â€” Full upsert, save-state sync, pull-from-cloud

### Infrastructure
- [x] `server.py` â€” Python stdlib HTTP server + REST API (port 3737)
- [x] `.tmp/` directory â€” scraper intermediates
- [x] `data/articles_store.json` â€” Local persistent store (**17 articles**)
- [x] Supabase `articles` table â€” **17 rows live**, RLS enabled, FTS index
- [x] Supabase `scrape_runs` table â€” audit log ready
- [x] Supabase views: `today_feed`, `saved_articles`

---

## âœ… Phase 4: Stylize â€” COMPLETE

- [x] **ZYROX brand** applied â€” `#BFF549` lime Ã— `#0D0D0D` black
- [x] **Typography** â€” Aspekta (headings) Â· Inter (body) Â· Geist Mono (monospace)
- [x] **Icon-only sidebar** â€” 72px, `ZX` lime logo, nav badges
- [x] **Source strip** â€” Ben's Bites / The Rundown / Reddit AI count cards
- [x] **Article grid** â€” Neumorphic dark cards with editorial images
- [x] **Filter chips** â€” All / Ben's Bites / The Rundown / Reddit AI
- [x] **Search** â€” Live client-side search across title + summary + author
- [x] **Modal** â€” Click-to-expand with source badge, image, tags, Read + Save actions
- [x] **Save / Unsave** â€” Persists to local JSON + syncs to Supabase instantly
- [x] **Toasts** â€” Success / error / info feedback toasts
- [x] **Skeleton loading** â€” Shimmer cards while fetching
- [x] **Empty state** â€” with Refresh button CTA
- [x] Dashboard verified live at **http://localhost:3737** âœ…

---

## ï¿½ Phase 5: Trigger â€” IN PROGRESS

- [x] Supabase cloud database live and populated
- [x] Auto-sync on scrape (background thread)
- [x] Auto-sync on save/unsave (background thread)
- [ ] **Windows Task Scheduler** â€” set daily scrape + sync at 6:00 AM
- [ ] **Maintenance Log** finalized in `gemini.md`
- [ ] Project marked COMPLETE

### Pending Task Scheduler Setup

```bat
REM Run this once in an elevated PowerShell to schedule daily scrape:
schtasks /create /tn "ZYROX-AI-Pulse" /tr "python C:\Users\Shrikant\Desktop\antigravity Project\scrapperrr\tools\scraper.py && python C:\Users\Shrikant\Desktop\antigravity Project\scrapperrr\tools\store.py" /sc daily /st 06:00 /ru SYSTEM
```

---

## ðŸ—’ï¸ Goals & Notes

### North Star
> A beautiful, interactive ZYROX-branded dashboard showing the latest AI articles from the last 24 hours â€” automatically refreshed daily, articles saveable, cloud-backed via Supabase.

### Key Decisions
| Decision | Choice | Reason |
|----------|--------|--------|
| Local store format | JSON | Zero deps, works offline, Supabase is replica |
| Article ID | SHA256 of URL | Stable, dedup-safe across runs |
| Server | Python stdlib `http.server` | No framework deps |
| Port | 3737 | 8080 was taken by another project |
| Supabase sync | Background threads | Non-blocking â€” dashboard never slows down |
| RLS policy | `anon` read/write | Single-user local-first dashboard |

### Remaining Optional Enhancements
- [ ] Reddit PRAW upgrade (add credentials to `.env`)
- [ ] Ben's Bites subscriber RSS (requires newsletter subscription)
- [ ] Real-time Supabase Realtime subscriptions in dashboard
- [ ] Task Scheduler daily automation
- [ ] `gemini.md` Maintenance Log finalization
